{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import os \n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "from modified_stable_diffusion import ModifiedStableDiffusionPipeline\n",
    "import PIL\n",
    "import open_clip\n",
    "from PIL import Image, ImageFilter\n",
    "import commpy.utilities as util\n",
    "\n",
    "def set_random_seed(seed=0):\n",
    "    torch.manual_seed(seed + 0)\n",
    "    torch.cuda.manual_seed(seed + 1)\n",
    "    torch.cuda.manual_seed_all(seed + 2)\n",
    "    np.random.seed(seed + 3)\n",
    "    torch.cuda.manual_seed_all(seed + 4)\n",
    "    random.seed(seed + 5)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='diffusion watermark')\n",
    "    parser.add_argument('--w_seed', default=999999, type=int)\n",
    "    parser.add_argument('--dataset', default='Gustavosta/Stable-Diffusion-Prompts',choices=['coco','stablediffusionDB','Gustavosta/Stable-Diffusion-Prompts'])\n",
    "    # parser.add_argument('--dataset', default='coco')\n",
    "    # parser.add_argument('--dataset', default='stablediffusionDB')\n",
    "    parser.add_argument('--model_path', default='../stable-diffusion-2-1-base')\n",
    "    # parser.add_argument('--model_path', default='../stable-diffusion-v1-4')\n",
    "    parser.add_argument('--image_length', default=512, type=int)\n",
    "    parser.add_argument('--secret_length', default=48, type=int)\n",
    "    parser.add_argument('--num_inference_steps', default=50, type=int)\n",
    "    parser.add_argument('--guidancescale', default=7.5, type=float)\n",
    "    parser.add_argument('--reverse_inference_steps', default=25, type=int)\n",
    "    \n",
    "    args =parser.parse_known_args()[0]\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    torch.set_printoptions(sci_mode=False,profile='full')\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    maxlength=150\n",
    "\n",
    "set_random_seed(seed=args.w_seed) \n",
    "# dataset\n",
    "dataset, prompt_key = get_dataset(args)\n",
    "dataset=promptdataset(dataset,prompt_key)\n",
    "scheduler = DPMSolverMultistepScheduler.from_pretrained(args.model_path, subfolder='scheduler')\n",
    "pipe = ModifiedStableDiffusionPipeline.from_pretrained(\n",
    "        args.model_path,\n",
    "        scheduler=scheduler,\n",
    "        torch_dtype=torch.float16,\n",
    "        revision='fp16',\n",
    "        )\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "#DiffuseTrace Model\n",
    "from encoder_decoder_pretrain.watermark_model import *\n",
    "encoder=Watermark(secret_length=args.secret_length).to(device)\n",
    "# encoder.load_state_dict(torch.load('./watermark_generation/model48bit.pth'))\n",
    "encoder.load_state_dict(torch.load('./model48bit_finetuned.pth'))\n",
    "encoder.eval()\n",
    "\n",
    "\n",
    "\n",
    "import commpy.channelcoding.convcode as cc\n",
    "memory = np.array(2, ndmin=1)\n",
    "g_matrix = np.array((0o5, 0o7), ndmin=2)\n",
    "trellis = cc.Trellis(memory, g_matrix)\n",
    "\n",
    "import cv2\n",
    "def measure_similarity(image, prompt, model, clip_preprocess, tokenizer, device):\n",
    "    with torch.no_grad():\n",
    "        image = clip_preprocess(image).unsqueeze(0).to(device)\n",
    "        image_features = model.encode_image(image).to(device)\n",
    "        \n",
    "        text = tokenizer([prompt]).to(device)\n",
    "        \n",
    "        text_features = model.encode_text(text)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    return (image_features @ text_features.T).mean(-1)\n",
    "    \n",
    "def compute_local_contrast(image):\n",
    "    mean = cv2.boxFilter(image, -1, (3, 3))\n",
    "    mean_sq = cv2.boxFilter(image ** 2, -1, (3, 3))\n",
    "    local_contrast = np.sqrt(mean_sq - mean ** 2)\n",
    "    return local_contrast\n",
    "\n",
    "def compute_niqe_score(image):\n",
    "    local_contrast = compute_local_contrast(image)\n",
    "    mean_contrast = np.mean(local_contrast)\n",
    "    std_contrast = np.std(local_contrast)\n",
    "    niqe_score = std_contrast / mean_contrast\n",
    "    return niqe_score\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "ref_model, _, ref_clip_preprocess = open_clip.create_model_and_transforms('ViT-g-14', pretrained='../CLIP-ViT-g-14-laion2B-s12B-b42K/open_clip_pytorch_model.bin', device=device)\n",
    "ref_tokenizer = open_clip.get_tokenizer('ViT-g-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metric,Loss,Error_correct,pred,target,Sim,Piqe,Niqe=[],[],[],[],[],[],[],[]\n",
    "\n",
    "for t in tqdm(range(1)):\n",
    "    initial_latents=get_random_latents(pipe,args)\n",
    "    init_latents=initial_latents.detach().clone()\n",
    "    secret_ori=np.random.choice([0, 1], size=(args.secret_length//2))\n",
    "    secret = cc.conv_encode(secret_ori,trellis,'cont')\n",
    "    secret_dec=secret.copy()\n",
    "    secret = torch.Tensor(secret).unsqueeze(-1).unsqueeze(-1).unsqueeze(0).to(device)\n",
    "    secret = secret.expand(-1,-1,64,64)\n",
    "    matrix1,mean,logvar=encoder(secret)\n",
    "    mean=mean.reshape(-1,4,64,64)\n",
    "    logvar=logvar.reshape(-1,4,64,64)\n",
    "    eps = torch.randn_like(logvar)\n",
    "    std = torch.exp(logvar / 2)\n",
    "    matrix = eps * std + mean\n",
    "    \n",
    "    init_latents=matrix.half()\n",
    "    # init_latents=initial_latents\n",
    "\n",
    "    # prompt=dataset[random.randint(1, len(dataset))][0:maxlength]\n",
    "    prompt=dataset[t][0:maxlength]\n",
    "    print(f\"current prompt: {prompt}\")\n",
    "    img1= pipe(prompt=prompt,num_inference_steps=args.num_inference_steps,\\\n",
    "    latents=init_latents,guidance_scale=args.guidancescale).images[0]\n",
    "    img1.show()\n",
    "    sim=measure_similarity(img1, prompt, ref_model, ref_clip_preprocess, ref_tokenizer, device)\n",
    "    Sim.append(sim[0].detach().cpu().numpy())\n",
    "    # print(sim)\n",
    "    \n",
    "    # import pypiqe\n",
    "    # piqescore=pypiqe.piqe(np.array(img1))[0]\n",
    "    # Piqe.append(piqescore)\n",
    "    # gray_image=img1.convert('L')\n",
    "    # cv2_image = cv2.cvtColor(np.array(gray_image), cv2.COLOR_GRAY2BGR)\n",
    "    # niqescore=compute_niqe_score(cv2_image)\n",
    "    \n",
    "    # import pyiqa\n",
    "    # niqe_metric = pyiqa.create_metric('niqe')\n",
    "    # niqescore=niqe_metric(img1)\n",
    "    # Niqe.append(niqescore.detach().cpu().numpy())\n",
    "    # img1.save('./sav.png')\n",
    "    # img1.save(f'{secret_dec}.png')\n",
    "    \n",
    "    # img= pipe(prompt=prompt,num_inference_steps=args.num_inference_steps,\\\n",
    "    #     latents=initial_latents,guidance_scale=args.guidancescale).images[0]\n",
    "    \n",
    "    # img1=compress_jpeg_to_pil(img1, 50)\n",
    "    \n",
    "    # img1 = img1.resize((int(args.image_length*0.3), int(args.image_length*0.3)), PIL.Image.BICUBIC)\n",
    "    \n",
    "    # img1 = img1.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "    \n",
    "    # from PIL import ImageEnhance\n",
    "    # enhancer = ImageEnhance.Contrast(img1)\n",
    "    # factor = 1.5\n",
    "    # img1= enhancer.enhance(factor)\n",
    "    \n",
    "    # img1 = np.array(img1, dtype=np.uint16)\n",
    "    # g_noise = np.random.randn(*img1.shape).astype(np.uint8)*0.5 \n",
    "    # noisy_array = np.clip(img1.astype(np.uint16) + g_noise, 0, 255).astype(np.uint8)\n",
    "    # img1 = Image.fromarray(noisy_array)\n",
    "    \n",
    "    # g_noise = (np.random.normal(0, 0.001, np.array(img1).shape) * 255).astype(np.uint8)\n",
    "    # img1 = Image.fromarray(np.clip(np.array(img1, dtype=np.int16) + g_noise, 0, 255).astype(np.uint8))\n",
    "    \n",
    "    # img1 = transforms.ColorJitter(brightness=2)(img1)\n",
    "    \n",
    "    # import cv2\n",
    "    # from bm3d import bm3d_rgb\n",
    "    # rgb_array = np.array(img1)\n",
    "    # denoised_red = bm3d_rgb(rgb_array,sigma_psd=30)\n",
    "    # img1 = Image.fromarray(denoised_red.astype(np.uint8))\n",
    "    \n",
    "    reverse_latents=reverse(img1,pipe,args).float()\n",
    "    reverse_latents = reverse_latents.view(1, -1)\n",
    "    x = encoder.decoder_projection(reverse_latents)\n",
    "    x = torch.reshape(x, (-1, *encoder.decoder_input_chw))\n",
    "    average_tensor1 = torch.mean(secret, dim=(-2, -1))\n",
    "    average_tensor2 = torch.round(torch.mean(encoder.decoder(x), dim=(-2, -1)))\n",
    "    average_tensor3 = torch.mean(encoder.decoder(x), dim=(-2, -1))\n",
    "    matrix_ori=torch.mean(matrix1, dim=(-2, -1))\n",
    "  \n",
    "    biterror=torch.sum(abs(average_tensor1-average_tensor2))\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    loss = mse_loss(average_tensor3, average_tensor1)\n",
    "    \n",
    "    decoded_bits = cc.viterbi_decode(np.array(average_tensor2[0].detach().cpu()).astype(float), trellis, 5)\n",
    "    num_bit_errors = util.hamming_dist(secret_ori, decoded_bits[:args.secret_length//2])\n",
    "    Error_correct.append(num_bit_errors)\n",
    "    \n",
    "    pred.append(average_tensor1.cpu().detach().numpy())\n",
    "    target.append(average_tensor2.cpu().detach().numpy())\n",
    "    Metric.append(biterror)\n",
    "    Loss.append(loss)\n",
    "    \n",
    "biterror=torch.mean(torch.stack(Metric))\n",
    "biterrper=biterror/args.secret_length\n",
    "metric=torch.mean(torch.stack(Loss))\n",
    "correctbit_err=np.mean(Error_correct)\n",
    "print(f'loss bits',f'{biterror.cpu().detach().numpy()}')\n",
    "print(f'bit acc percentage {(1-biterrper)*100:.2f}%')\n",
    "print(f'loss',f'{metric.cpu().detach()}')\n",
    "print(f'bit error average',f'{biterror.detach().cpu().numpy():.2f}')\n",
    "print(f'bit error correct average',f'{correctbit_err:.2f}')\n",
    "print(f'Clip score average',f'{np.mean(Sim):.4f}')\n",
    "# print(f'NIQE score average',f'{np.mean(Niqe):.4f}')\n",
    "# print(f'PIQE score average',f'{np.mean(Piqe):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
